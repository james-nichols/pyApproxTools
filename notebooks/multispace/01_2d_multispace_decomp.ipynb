{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\def \\dot #1#2{\\left\\langle #1, #2 \\right\\rangle}$\n",
    "$\\def \\adot #1#2{\\left\\langle #1, #2 \\right\\rangle}$\n",
    "$\\def \\cD {\\mathcal{D}}$\n",
    "$\\def \\cM {\\mathcal{M}}$\n",
    "$\\def \\bc {\\mathbf{c}}$\n",
    "$\\def \\bv {\\mathbf{v}}$\n",
    "$\\def \\bG {\\mathbf{G}}$\n",
    "\n",
    "### Multispace decomposition of the two dimensional field solution\n",
    "\n",
    "$y\\in\\mathbb{R}^2$, $a(y) = y_1 \\chi_{D_1}(x) + y_2 \\chi_{D_2}(x)$, and $D_1 = [0,1/2) \\times [0,1]$ and $D_2 = [1/2, 1] \\times [0,1]$, and $\\chi_{D_1}$, $\\chi_{D_2}$ are the indicator functions on $D_1$, $D_2$.\n",
    "\n",
    "We have \n",
    "$$\n",
    "a(y) = \\bar{a} + c(y_1 \\chi_{D_1} + y_2 \\chi_{D_2})\n",
    "$$\n",
    "\n",
    "We define the operators $A_0$, $A_1$ and $A_2$ in the inner product\n",
    "$$\n",
    "\\dot{A_0 u}{v}_V = \\int_D \\nabla u \\cdot \\nabla v \\, \\mathrm{d} x\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\dot{A_1 u}{v}_V = \\int_{D} \\chi_{D_1} \\nabla u \\cdot \\nabla v \\, \\mathrm{d} x = \\int_{D_1} \\nabla u \\cdot \\nabla v \\, \\mathrm{d} x\n",
    "$$\n",
    "and similar for $A_2$. Recall that $V=H_0^1(D)$. Now let us assume that both $a$ is constant. We can re-write the PDE problem in its weak form as\n",
    "\n",
    "$$\n",
    "\\left ( \\bar{a}A_0 + c y_1 A_1 + c y_2 A_2 \\right) u = f\n",
    "$$\n",
    "\n",
    "The essence of the is to see that we can pull out the \"scale\" of the field out the front, and we are left with one more parameter which is the amount of difference in the field between $D_1$ and $D_2$, that is,\n",
    "$$\n",
    "a(y_1, y_2) = a(y_m, y_d) = y_m \\left( 1 + y_d (\\chi_{D_1} - \\chi_{D_2}) \\right)\n",
    "$$\n",
    "where we have defined \n",
    "$$\n",
    "y_m = \\bar{a} + c\\frac{y_1 + y_2}{2} \\quad \\text{and} \\quad y_d = c \\frac{y_1-y_2}{2} y_m^{-1}\n",
    "$$\n",
    "\n",
    "Now, we write $u_0\\in H_0^1(D)$, $u_1\\in H_0^1(D_1)$ and $u_2 \\in H_0^1(D_2)$ for the solutions of \n",
    "$$\n",
    "A_0 u_0 = f \\quad A_1 u_1 = \\chi_{D_1} f \\quad A_2 u_2 = \\chi_{D_2} f\n",
    "$$\n",
    "\n",
    "__Then the solution is given by__\n",
    "\n",
    "$$\n",
    "\\large\n",
    "u = \\frac{1}{y_m} \\left( u_0 - y_d \\left( \\frac{u_1}{1+y_d} - \\frac{u_2}{1-y_d}\\right)\\right)\n",
    "$$\n",
    "\n",
    "I show this in a write-up somehwere. Point is, it's a 3-dimensional manifold (the solution is composed of only $u_0, u_1$ and $u_2$ indexed by two parameters, $y_1$ and $y_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import importlib\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pdb\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"../../\")\n",
    "import pyApproxTools as pat\n",
    "importlib.reload(pat)\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "def make_soln(points, fem_div, a_bar=1.0, c=0.5, f=1.0, verbose=False):\n",
    "    \n",
    "    solns = []\n",
    "    fields = []\n",
    "\n",
    "    for p in points:\n",
    "        field = pat.PWConstantSqDyadicL2(a_bar + c * p.reshape((2,2)))\n",
    "        fields.append(field)\n",
    "        # Then the fem solver (there a faster way to do this all at once? This will be huge...\n",
    "        fem_solver = pat.DyadicFEMSolver(div=fem_div, rand_field = field, f = 1)\n",
    "        fem_solver.solve()\n",
    "        solns.append(fem_solver.u)\n",
    "        \n",
    "    return solns, fields\n",
    "\n",
    "def make_2d_soln(points, fem_div, a_bar=1.0, c=0.5, f=1.0, verbose=False):\n",
    "    \n",
    "    solns = []\n",
    "    fields = []\n",
    "\n",
    "    for p in points:\n",
    "        field = pat.PWConstantSqDyadicL2(a_bar + c * np.repeat(p[:,np.newaxis], 2, axis=1).T)\n",
    "        fields.append(field)\n",
    "        # Then the fem solver (there a faster way to do this all at once? This will be huge...\n",
    "        fem_solver = pat.DyadicFEMSolver(div=fem_div, rand_field = field, f = 1)\n",
    "        fem_solver.solve()\n",
    "        solns.append(fem_solver.u)\n",
    "        \n",
    "    return solns, fields\n",
    "\n",
    "fem_div = 7\n",
    "a_bar = 0.1\n",
    "c = 2.0\n",
    "\n",
    "def diffusion_pde(points):\n",
    "    solns, fields = make_soln(points, fem_div=fem_div, a_bar=a_bar, c=c)\n",
    "    return solns\n",
    "    \n",
    "def diffusion_2d_pde(points):\n",
    "    solns, fields = make_2d_soln(points, fem_div=fem_div, a_bar=a_bar, c=c)\n",
    "    return solns\n",
    "\n",
    "def soln_loc_2d_pde(points):\n",
    "    ym = a_bar + points.mean(axis=1)\n",
    "    yd = c * (points[:,0] - points[:,1]) / (2*ym)\n",
    "    \n",
    "    soln_loc = np.zeros((points.shape[0], 3))\n",
    "    soln_loc[:,0] = 1.0 / ym\n",
    "    soln_loc[:,1] = - yd / (ym * (1 + yd))\n",
    "    soln_loc[:,2] = yd / (ym * (1 - yd))\n",
    "    \n",
    "    return soln_loc\n",
    "\n",
    "# For the sake of testing we make these solutions\n",
    "y1 = np.array([[1, 1e10]])\n",
    "y2 = np.array([[1e10, 1]])\n",
    "u0, a0 = make_2d_soln(np.array([[1,1]]), fem_div, a_bar=0, c=1)\n",
    "u1, a1 = make_2d_soln(y1, fem_div, a_bar=0, c=1)\n",
    "u2, a2 = make_2d_soln(y2, fem_div, a_bar=0, c=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ...So, what are we doing?\n",
    "\n",
    "Well, lets just say we have any old parametric function $u(y)$ that defines a set of points $\\cM = \\{u(y) : y\\in Y \\}$. Doesn't have to be the PDE. Lets assume $Y = [0,1]^d$ and we are interested in the push forward measure of the uniform measure on $Y$, which we call $\\mu$ and is supported on $\\cM$.\n",
    "\n",
    "Our first step is to construct a PCA approximation $\\mu_1$ and calculate the lifting operator.\n",
    "\n",
    "Then we look at the $d$ different splittings available. There'sa variety of choice criteria available.\n",
    "\n",
    "Then we create the next splitting, and calculate the $d$ possible splits in that cell...\n",
    "\n",
    "At each step we have $(k+1)d$ possible criteria to search from.\n",
    "\n",
    "We should also have the multilinear estimator built.\n",
    "\n",
    "Oh my god this is doing my head in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we need some tree structure to keep track of the splitting tree    \n",
    "from anytree import NodeMixin, RenderTree\n",
    "import itertools\n",
    "\n",
    "def PCA(U, eig_tol=1e-12):\n",
    "    \n",
    "    u_mean = U @ (np.ones(U.n) / U.n)\n",
    "    u_mean_cor = np.zeros(U.n)\n",
    "    for i, u in enumerate(U):\n",
    "        u_mean_cor[i] = u_mean.dot(u)\n",
    "    u_mnsq = u_mean.dot(u_mean)\n",
    "    \n",
    "    mean_free_G = np.copy(U.G)\n",
    "    for i in range(U.n):\n",
    "        for j in range(U.n):\n",
    "            mean_free_G[i,j] -= (u_mean_cor[i] + u_mean_cor[j] + u_mnsq)\n",
    "    \n",
    "    sig, V = sp.linalg.eigh(mean_free_G)\n",
    "\n",
    "    V = V[:,::-1]\n",
    "    sig = sig[::-1]\n",
    "    V = V[:,sig > eig_tol]\n",
    "    sig = sig[sig > eig_tol]\n",
    "\n",
    "    PCA_Basis = U @ V @ np.diag(np.sqrt(1.0/sig))\n",
    "\n",
    "    return PCA_Basis, sig, u_mean\n",
    "\n",
    "class ParamPWBasis(pat.PWBasis):\n",
    "    \"\"\" Just a class that has the parameters associated with the basis at the same time \"\"\"\n",
    "    def __init__(self, vecs=None, ys=None, G=None, values_flat=None, pre_allocate=0, file_name=None):\n",
    "        super().__init__(vecs=vecs, G=G, values_flat=values_flat, pre_allocate=pre_allocate, file_name=file_name)\n",
    "        \n",
    "        if ys is not None:\n",
    "            assert ys.shape[0] == len(vecs)\n",
    "            self.ys = ys\n",
    "        \n",
    "    def add_vec(self, vec, y):\n",
    "        \"\"\" Add just one vector, so as to make the new Grammian calculation quick \"\"\"\n",
    "        super().add_vec(vec)\n",
    "        if ys is not None:\n",
    "            self.ys = np.vstack((self.ys, y))\n",
    "\n",
    "    def append(self, other, ys):\n",
    "        \"\"\" Add just one vector, so as to make the new Grammian calculation quick \"\"\"\n",
    "        super().append(other)\n",
    "        if ys is not None:\n",
    "            self.ys = np.vstack((self.ys, ys))\n",
    "    \n",
    "    def mask(self, y_range):\n",
    "        return np.all((self.ys > y_range[:,0]) & (self.ys <= y_range[:,1]), axis=-1)\n",
    " \n",
    "    def __getitem__(self, idx):\n",
    "        if self._is_herm_trans:\n",
    "            raise IndexError(self.__name__ + ': can not access rows of Hermitian of basis')\n",
    "\n",
    "        if isinstance(idx, int):\n",
    "            return self._vecs[idx]\n",
    "\n",
    "        elif isinstance(idx, slice):\n",
    "            sub = type(self)(vecs=self._vecs[idx], ys=self.ys[idx], values_flat=self._values_flat[:,:,idx])\n",
    "            if not np.any(self._vec_is_new):\n",
    "                sub._G = self._G[idx, idx]\n",
    "            return sub\n",
    "\n",
    "        elif hasattr(idx, '__len__') and len(idx) == len(self): \n",
    "            # NOT CONFIDENT THAT THIS WORKS... but in this case idx is a boolean mask...\n",
    "            sub = type(self)(vecs=list(itertools.compress(self._vecs, idx)), ys=self.ys[idx], values_flat=self._values_flat[:,:,idx])\n",
    "            if not np.any(self._vec_is_new):\n",
    "                sub._G = self._G[idx,idx]\n",
    "            return sub\n",
    "\n",
    "        else:\n",
    "            raise TypeError(self.__class__.__name__ + ': idx type incorrect')\n",
    "\n",
    "\n",
    "class LocalNormalEstimator(NodeMixin):\n",
    "    \n",
    "    def __init__(self, U, f, y_range, min_N=500, parent=None):\n",
    "        \n",
    "        self.U = U\n",
    "\n",
    "        self.y_range = y_range\n",
    "        self.d = y_range.shape[1]\n",
    "        self.f = f\n",
    "        self._min_N = min_N\n",
    "\n",
    "        self._mask = U.mask(self.y_range)\n",
    "\n",
    "        if self._mask.sum() < self._min_N:\n",
    "            ys_new = np.random.random((self._min_N - self._mask.sum(), self.d)) * (y_range[:, 1] - y_range[:, 0]) + y_range[:, 0]\n",
    "            U_new = self.f(ys_new)\n",
    "            print(U_new, ys_new)\n",
    "            self.U.append(U_new, ys_new)\n",
    "            self._mask = U.mask(self.y_range)\n",
    "\n",
    "        self._local_U = self.U[self._mask]\n",
    "        self.Phi, self.sigma_sq = PCA(self._local_U)\n",
    "        \n",
    "        self.parent = parent\n",
    "        \n",
    "    def cond_variance(self, Wm):\n",
    "        \n",
    "        self.GW = Wm.T @ self.Phi @ np.diag(np.sqrt(self.sigma_sq))\n",
    "        self.r = np.linalg.matrix_rank(self.GW)\n",
    "        \n",
    "        Psi_til, S_til, Phi_til = np.linalg.svd(self.GW)\n",
    "        Phi_perp = Phi_til[r:].T\n",
    "        \n",
    "        self._cond_variance = np.trace(Phi_perp.T @ np.diag(self.sigma_sq) @ Phi_perp)\n",
    "        \n",
    "        return self._cond_variance\n",
    "        \n",
    "    def variance(self):\n",
    "        return np.sqrt(self.sigma_sq.prod())\n",
    "        \n",
    "    def children_angle(self, angle_tol=1e-10):\n",
    "        # Some weird criteria I'm imagining to choose the children that have the biggest difference\n",
    "        # in span of the PCA space...\n",
    "        \n",
    "        self.child_angles = np.zeros((self.d, 3))\n",
    "        self.ranks = np.zeros((self.d, 3))\n",
    "        for i, (child_l, child_r) in enumerate(zip(self.cand_child_l, self.cand_child_r)):\n",
    "\n",
    "            print(self.sigma_sq)\n",
    "            print(child_l.sigma_sq)\n",
    "            print(child_r.sigma_sq)\n",
    "            print(self.sigma_sq[0] / self.sigma_sq[-1], child_l.sigma_sq[0] / child_l.sigma_sq[-1], child_r.sigma_sq[0] / child_r.sigma_sq[-1])\n",
    "            print(self.sigma_sq.prod(), child_l.sigma_sq.prod(), child_r.sigma_sq.prod())\n",
    "            print(self.sigma_sq.prod()**(1.0/len(self.sigma_sq)), child_l.sigma_sq.prod()**(1.0/len(child_l.sigma_sq)), child_r.sigma_sq.prod()**(1.0/len(child_r.sigma_sq)))\n",
    "            G_p_l = (self.Phi @ np.diag(np.sqrt(self.sigma_sq))).H @ child_l.Phi @ np.diag(np.sqrt(child_l.sigma_sq))\n",
    "            S_p_l = sp.linalg.svd(G_p_l, compute_uv=False)\n",
    "\n",
    "            print(G_p_l)\n",
    "            print(S_p_l)\n",
    "            \n",
    "            G_p_r = (self.Phi @ np.diag(np.sqrt(self.sigma_sq))).H @ child_r.Phi @ np.diag(np.sqrt(child_r.sigma_sq))\n",
    "            S_p_r = sp.linalg.svd(G_p_r, compute_uv=False)\n",
    "            print(G_p_r)\n",
    "            print(S_p_r)\n",
    "            \n",
    "            G_l_r = (child_l.Phi @ np.diag(np.sqrt(child_l.sigma_sq))).H @ child_r.Phi @ np.diag(np.sqrt(child_r.sigma_sq))\n",
    "            S_l_r = sp.linalg.svd(G_l_r, compute_uv=False)\n",
    "            print(G_l_r)\n",
    "            print(S_l_r)\n",
    "            \n",
    "            self.child_angles[i, 0] = S_p_l[-1]\n",
    "            self.child_angles[i, 1] = S_p_r[-1]\n",
    "            self.child_angles[i, 2] = S_l_r[-1]\n",
    "        \n",
    "            self.ranks[i, 0] = np.linalg.matrix_rank(G_p_l)\n",
    "            self.ranks[i, 1] = np.linalg.matrix_rank(G_p_r)\n",
    "            self.ranks[i, 2] = np.linalg.matrix_rank(G_l_r)\n",
    "            \n",
    "    def children_W_2(self):\n",
    "        self.W_adj = np.zeros(self.d)\n",
    "        \n",
    "        for i, (child_l, child_r) in enumerate(zip(self.cand_child_l, self.cand_child_r)):\n",
    "            \n",
    "            lr_CG = child_l.Phi.H @ child_r.Phi\n",
    "            \n",
    "            W_adj[i] = np.trace(np.diag(np.sqrt(child_l.sigma_sq)) @ lr_CG @ np.diag(child_r.sigma_sq) \\\n",
    "                     @ lr.CG.T @ np.diag(np.sqrt(child_l.sigma_sq))\n",
    "            \n",
    "        \n",
    "    \n",
    "    def generate_potential_children(self):\n",
    "        # Loop through all d dimensions, do the splitting (by creating) and save\n",
    "        \n",
    "        self.cand_child_l = []\n",
    "        self.cand_child_r = []ts\n",
    "        for i in range(d):\n",
    "            \n",
    "            y_range_l = np.copy(self.y_range)\n",
    "            y_range_l[i,1] = self.y_range[i,:].mean()\n",
    "            y_range_r = np.copy(self.y_range)\n",
    "            y_range_r[i,0] = self.y_range[i,:].mean()\n",
    "            \n",
    "            # The children are set up with no parent at first. They are \"detached\" for now. The ones we choose will become attached\n",
    "            self.cand_child_l.append(LocalNormalEstimator(self.U, self.f, y_range_l, min_N=self._min_N, parent=None))\n",
    "            self.cand_child_r.append(LocalNormalEstimator(self.U, self.f, y_range_r, min_N=self._min_N, parent=None))\n",
    "        \n",
    "    def split(self):\n",
    "        \n",
    "        self.children_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "d = 2\n",
    "\n",
    "y_range = np.zeros((d,2))\n",
    "y_range[:,1] = 1\n",
    "\n",
    "np.random.seed(1)\n",
    "points = np.random.random((N, d)) * (y_range[:, 1] - y_range[:, 0]) + y_range[:, 0]\n",
    "us = diffusion_2d_pde(points)\n",
    "U = ParamPWBasis(vecs=us, ys=points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_range = np.zeros((d,2))\n",
    "y_range[:,1] = 1\n",
    "\n",
    "l = LocalNormalEstimator(U, diffusion_2d_pde, y_range, min_N=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.048646783723948324\n",
      "[<pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x107ea3c50>, <pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x107e772e8>, <pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x102c28668>] [[0.97508806 0.55665319]\n",
      " [0.95780317 0.64156621]\n",
      " [0.69500386 0.48599067]]\n",
      "[<pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x107eac748>, <pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x107eac390>, <pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x107eac1d0>, <pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x107eacdd8>, <pyApproxTools.pw_vector.PWLinearSqDyadicH1 object at 0x107eaccc0>] [[0.60431048 0.27477396]\n",
      " [0.92618143 0.45936672]\n",
      " [0.39487561 0.48163126]\n",
      " [0.17395567 0.06316476]\n",
      " [0.13507916 0.25283108]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 106 is out of bounds for axis 1 with size 106",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-143-9a671186805a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_potential_children\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren_angle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-021c72046396>\u001b[0m in \u001b[0;36mgenerate_potential_children\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m             \u001b[0;31m# The children are set up with no parent at first. They are \"detached\" for now. The ones we choose will become attached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcand_child_l\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocalNormalEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_range_l\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_N\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcand_child_r\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLocalNormalEstimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_range_r\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_N\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_min_N\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-021c72046396>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, U, f, y_range, min_N, parent)\u001b[0m\n\u001b[1;32m     81\u001b[0m             \u001b[0mU_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mys_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mU_new\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys_new\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mU\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0my_range\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-140-021c72046396>\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other, ys)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;34m\"\"\" Add just one vector, so as to make the new Grammian calculation quick \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mys\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/LJLL_2017/pyApproxTools/pyApproxTools/pw_basis.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     88\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;34m\"\"\" Add just one vector, so as to make the new Grammian calculation quick \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_values_flat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/LJLL_2017/pyApproxTools/pyApproxTools/basis.py\u001b[0m in \u001b[0;36mappend\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    265\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_U\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_V\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_S\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 267\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    268\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/projects/LJLL_2017/pyApproxTools/pyApproxTools/basis.py\u001b[0m in \u001b[0;36mG\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     81\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vec_is_new\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_G\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_G\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vec_is_new\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfull\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 106 is out of bounds for axis 1 with size 106"
     ]
    }
   ],
   "source": [
    "print(l.variance())\n",
    "l.generate_potential_children()\n",
    "l.children_angle()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "103"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(U.ys)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "points_new = np.random.random((10, d)) * (y_range[:, 1] - y_range[:, 0]) + y_range[:, 0]\n",
    "np.vstack((points, points_new)).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[:,:] < r[:,0]\n",
    "print(y)\n",
    "r[:,0] < y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=[3,4]\n",
    "b = [4,4]\n",
    "a.append(b[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 2)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "U.n\n",
    "points.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
